{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MadhuShree-A/TIC-based-Image-Compression/blob/main/TIC_streamlit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y compressai\n",
        "!pip install compressai==1.2.4\n",
        "!pip install -q torch torchvision streamlit pyngrok pillow scikit-image nbformat\n",
        "\n",
        "!git --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0y9pQmSSMZf",
        "outputId": "aa246b2c-3767-451d-dda5-cf95cdf2e968"
      },
      "id": "i0y9pQmSSMZf",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping compressai as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting compressai==1.2.4\n",
            "  Downloading compressai-1.2.4.tar.gz (79 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.9/79.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from compressai==1.2.4) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from compressai==1.2.4) (1.16.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from compressai==1.2.4) (3.10.0)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from compressai==1.2.4) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from compressai==1.2.4) (0.24.0+cu126)\n",
            "Collecting pytorch-msssim (from compressai==1.2.4)\n",
            "  Downloading pytorch_msssim-1.0.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->compressai==1.2.4) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->compressai==1.2.4) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->compressai==1.2.4) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->compressai==1.2.4) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->compressai==1.2.4) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->compressai==1.2.4) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->compressai==1.2.4) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->compressai==1.2.4) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->compressai==1.2.4) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->compressai==1.2.4) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->compressai==1.2.4) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->compressai==1.2.4) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->compressai==1.2.4) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->compressai==1.2.4) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->compressai==1.2.4) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->compressai==1.2.4) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->compressai==1.2.4) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->compressai==1.2.4) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->compressai==1.2.4) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->compressai==1.2.4) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->compressai==1.2.4) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->compressai==1.2.4) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->compressai==1.2.4) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->compressai==1.2.4) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->compressai==1.2.4) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->compressai==1.2.4) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->compressai==1.2.4) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->compressai==1.2.4) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->compressai==1.2.4) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->compressai==1.2.4) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->compressai==1.2.4) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->compressai==1.2.4) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.7.1->compressai==1.2.4) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.7.1->compressai==1.2.4) (3.0.3)\n",
            "Downloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\n",
            "Building wheels for collected packages: compressai\n",
            "  Building wheel for compressai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for compressai: filename=compressai-1.2.4-cp312-cp312-linux_x86_64.whl size=296694 sha256=6ec9df5b0bb0da9c27a955af47c01447e9d25ff971dbd9d8c8f0da653adbd9df\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/3d/0b/34c8476f346efaa9328f44a850c8e4a59ba376c7690b743346\n",
            "Successfully built compressai\n",
            "Installing collected packages: pytorch-msssim, compressai\n",
            "Successfully installed compressai-1.2.4 pytorch-msssim-1.0.0\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m121.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hgit version 2.34.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, subprocess\n",
        "\n",
        "repos = [\n",
        "    'https://github.com/lumingzzz/TIC.git',      # community implementation (DCC 2022)\n",
        "    'https://github.com/NJUVISION/TIC.git',     # possible author/org path\n",
        "    'https://github.com/NJUVISION/MPA.git'      # general fallback\n",
        "]\n",
        "\n",
        "cloned = []\n",
        "for r in repos:\n",
        "    name = r.split('/')[-1].replace('.git','')\n",
        "    target = f'/content/{name}'\n",
        "    if os.path.exists(target):\n",
        "        print('Already present:', target)\n",
        "        cloned.append(target)\n",
        "        continue\n",
        "    try:\n",
        "        print('Cloning', r)\n",
        "        subprocess.run(['git','clone',r,target], check=True)\n",
        "        print('Cloned to', target)\n",
        "        cloned.append(target)\n",
        "    except Exception as e:\n",
        "        print(' Failed to clone', r, '->', e)\n",
        "\n",
        "print('\\nCloned repos:', cloned)\n"
      ],
      "metadata": {
        "id": "XKV5QUGCZrP4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8b79917-e6f4-49f6-c309-85db308e5b3b"
      },
      "id": "XKV5QUGCZrP4",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning https://github.com/lumingzzz/TIC.git\n",
            "Cloned to /content/TIC\n",
            "Already present: /content/TIC\n",
            "Cloning https://github.com/NJUVISION/MPA.git\n",
            "Cloned to /content/MPA\n",
            "\n",
            "Cloned repos: ['/content/TIC', '/content/TIC', '/content/MPA']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0929ef4b",
      "metadata": {
        "id": "0929ef4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "285109b5-550d-4119-8a84-17aa6c13b6c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ No pretrained TIC weights found â€” fallback to CompressAI pretrained model will be used.\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "\n",
        "found_weights = []\n",
        "for root, _, files in os.walk('/content'):\n",
        "    for f in files:\n",
        "        if f.endswith('.pth') or f.endswith('.pt'):\n",
        "            found_weights.append(os.path.join(root, f))\n",
        "\n",
        "if found_weights:\n",
        "    print(\"âœ… Found pretrained weight files:\")\n",
        "    for f in found_weights:\n",
        "        print(\"  \", f)\n",
        "else:\n",
        "    print(\"âš ï¸ No pretrained TIC weights found â€” fallback to CompressAI pretrained model will be used.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "617facb6",
      "metadata": {
        "id": "617facb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84bcd894-90d0-4546-9f5a-ad0120fdd364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ‘‰ Visit https://dashboard.ngrok.com/get-started/your-authtoken to get your auth token.\n",
            "Paste your ngrok authtoken here: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "âœ… ngrok authtoken configured successfully.\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "import getpass\n",
        "\n",
        "print(\"ðŸ‘‰ Visit https://dashboard.ngrok.com/get-started/your-authtoken to get your auth token.\")\n",
        "NGROK_AUTH_TOKEN = getpass.getpass(\"Paste your ngrok authtoken here: \")\n",
        "\n",
        "ngrok.kill()\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "print(\"âœ… ngrok authtoken configured successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''utils_py = r\"\"\"\n",
        "import io, torch\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from skimage.metrics import peak_signal_noise_ratio as compare_psnr, structural_similarity as compare_ssim\n",
        "\n",
        "def load_image_as_tensor(pil_img):\n",
        "    transform = T.Compose([T.ToTensor()])\n",
        "    return transform(pil_img).unsqueeze(0)\n",
        "\n",
        "def tensor_to_pil(x):\n",
        "    x = x.detach().cpu().clamp(0,1)\n",
        "    if x.ndim == 4:\n",
        "        x = x[0]\n",
        "    arr = (x.numpy()*255).round().astype('uint8').transpose(1,2,0)\n",
        "    return Image.fromarray(arr)\n",
        "\n",
        "def compute_metrics(img1, img2):\n",
        "    a, b = np.array(img1).astype('float32'), np.array(img2).astype('float32')\n",
        "    psnr = compare_psnr(a, b, data_range=255)\n",
        "    ssim = compare_ssim(a, b, data_range=255, channel_axis=-1)\n",
        "    return psnr, ssim\n",
        "\n",
        "def pad_to_multiple_of(x, div=64):\n",
        "    _, _, h, w = x.shape\n",
        "    new_h = int(np.ceil(h/div)*div)\n",
        "    new_w = int(np.ceil(w/div)*div)\n",
        "    return F.pad(x, (0, new_w-w, 0, new_h-h)), (h, w)\n",
        "\n",
        "def load_model(device='cpu'):\n",
        "    # âœ… Fallback: use pretrained CompressAI Cheng2020 model\n",
        "    from compressai.zoo import cheng2020_anchor\n",
        "    model = cheng2020_anchor(quality=6, pretrained=True).eval().to(device)\n",
        "    return ('compressai_cheng2020', model)\n",
        "\n",
        "def compress_and_decompress(model_info, pil_img, device='cpu'):\n",
        "    tag, model = model_info\n",
        "    x = load_image_as_tensor(pil_img).to(device)\n",
        "    x_padded, orig_size = pad_to_multiple_of(x, div=64)\n",
        "    with torch.no_grad():\n",
        "        out_enc = model.compress(x_padded)\n",
        "        comp_bytes = sum(len(s) for s in out_enc['strings'])\n",
        "        out_dec = model.decompress(out_enc['strings'], out_enc['shape'])\n",
        "        x_hat = out_dec['x_hat'].clamp(0,1)\n",
        "    h, w = orig_size\n",
        "    x_hat = x_hat[..., :h, :w]\n",
        "    return x_hat, comp_bytes\n",
        "\"\"\"\n",
        "open(\"/content/utils.py\",\"w\").write(utils_py)\n",
        "print(\" Created utils.py\")\n",
        "\n",
        "# ============================================\n",
        "# ðŸ§© STEP 6 â€” CREATE STREAMLIT APP FILE\n",
        "# ============================================\n",
        "app_py = r\"\"\"\n",
        "import streamlit as st\n",
        "import torch\n",
        "from PIL import Image\n",
        "import io\n",
        "from utils import load_model, compress_and_decompress, tensor_to_pil, compute_metrics\n",
        "\n",
        "st.set_page_config(page_title=\"Transformer Image Compression\", layout=\"wide\")\n",
        "st.title(\"ðŸ§  Deep Learning Image Compression Demo\")\n",
        "st.caption(\"Using pretrained CompressAI (Cheng2020) model\")\n",
        "\n",
        "uploaded = st.file_uploader(\"Upload an image\", type=['png','jpg','jpeg'])\n",
        "\n",
        "if uploaded:\n",
        "    pil_img = Image.open(uploaded).convert('RGB')\n",
        "\n",
        "    # ðŸ”’ Limit image size to prevent OOM crash\n",
        "    max_size = 512\n",
        "    if pil_img.width > max_size or pil_img.height > max_size:\n",
        "        pil_img.thumbnail((max_size, max_size))\n",
        "        st.warning(f\"Image resized to {pil_img.size} to prevent out-of-memory issues.\")\n",
        "\n",
        "    st.image(pil_img, caption=\"Original Image\", use_column_width=True)\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    if 'model_info' not in st.session_state:\n",
        "        with st.spinner('Loading pretrained model...'):\n",
        "            st.session_state['model_info'] = load_model(device)\n",
        "\n",
        "    model_info = st.session_state['model_info']\n",
        "\n",
        "    try:\n",
        "        with st.spinner('Compressing and reconstructing...'):\n",
        "            x_hat_tensor, comp_bytes = compress_and_decompress(model_info, pil_img, device)\n",
        "            rec_img = tensor_to_pil(x_hat_tensor)\n",
        "            psnr, ssim = compute_metrics(pil_img, rec_img)\n",
        "            bpp = (comp_bytes * 8) / (pil_img.width * pil_img.height)\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "        col1.image(pil_img, caption=\"Original\")\n",
        "        col2.image(rec_img, caption=\"Reconstructed\")\n",
        "\n",
        "        st.markdown(f\"**Bits per pixel:** {bpp:.4f}\")\n",
        "        st.markdown(f\"**PSNR:** {psnr:.2f} dB\")\n",
        "        st.markdown(f\"**SSIM:** {ssim:.4f}\")\n",
        "\n",
        "    except RuntimeError as e:\n",
        "        st.error(f\"Compression failed: {str(e)}. Try a smaller image.\")\n",
        "\"\"\"\n",
        "open(\"/content/app.py\",\"w\").write(app_py)\n",
        "print(\"âœ… Created app.py\")'''\n"
      ],
      "metadata": {
        "id": "bmqDf6xNbnPQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "a965164c-f4d3-4dbf-8a15-38e2dda3980c"
      },
      "id": "bmqDf6xNbnPQ",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'utils_py = r\"\"\"\\nimport io, torch\\nimport torchvision.transforms as T\\nfrom PIL import Image\\nimport numpy as np\\nimport torch.nn.functional as F\\nfrom skimage.metrics import peak_signal_noise_ratio as compare_psnr, structural_similarity as compare_ssim\\n\\ndef load_image_as_tensor(pil_img):\\n    transform = T.Compose([T.ToTensor()])\\n    return transform(pil_img).unsqueeze(0)\\n\\ndef tensor_to_pil(x):\\n    x = x.detach().cpu().clamp(0,1)\\n    if x.ndim == 4:\\n        x = x[0]\\n    arr = (x.numpy()*255).round().astype(\\'uint8\\').transpose(1,2,0)\\n    return Image.fromarray(arr)\\n\\ndef compute_metrics(img1, img2):\\n    a, b = np.array(img1).astype(\\'float32\\'), np.array(img2).astype(\\'float32\\')\\n    psnr = compare_psnr(a, b, data_range=255)\\n    ssim = compare_ssim(a, b, data_range=255, channel_axis=-1)\\n    return psnr, ssim\\n\\ndef pad_to_multiple_of(x, div=64):\\n    _, _, h, w = x.shape\\n    new_h = int(np.ceil(h/div)*div)\\n    new_w = int(np.ceil(w/div)*div)\\n    return F.pad(x, (0, new_w-w, 0, new_h-h)), (h, w)\\n\\ndef load_model(device=\\'cpu\\'):\\n    # âœ… Fallback: use pretrained CompressAI Cheng2020 model\\n    from compressai.zoo import cheng2020_anchor\\n    model = cheng2020_anchor(quality=6, pretrained=True).eval().to(device)\\n    return (\\'compressai_cheng2020\\', model)\\n\\ndef compress_and_decompress(model_info, pil_img, device=\\'cpu\\'):\\n    tag, model = model_info\\n    x = load_image_as_tensor(pil_img).to(device)\\n    x_padded, orig_size = pad_to_multiple_of(x, div=64)\\n    with torch.no_grad():\\n        out_enc = model.compress(x_padded)\\n        comp_bytes = sum(len(s) for s in out_enc[\\'strings\\'])\\n        out_dec = model.decompress(out_enc[\\'strings\\'], out_enc[\\'shape\\'])\\n        x_hat = out_dec[\\'x_hat\\'].clamp(0,1)\\n    h, w = orig_size\\n    x_hat = x_hat[..., :h, :w]\\n    return x_hat, comp_bytes\\n\"\"\"\\nopen(\"/content/utils.py\",\"w\").write(utils_py)\\nprint(\" Created utils.py\")\\n\\n# ============================================\\n# ðŸ§© STEP 6 â€” CREATE STREAMLIT APP FILE\\n# ============================================\\napp_py = r\"\"\"\\nimport streamlit as st\\nimport torch\\nfrom PIL import Image\\nimport io\\nfrom utils import load_model, compress_and_decompress, tensor_to_pil, compute_metrics\\n\\nst.set_page_config(page_title=\"Transformer Image Compression\", layout=\"wide\")\\nst.title(\"ðŸ§  Deep Learning Image Compression Demo\")\\nst.caption(\"Using pretrained CompressAI (Cheng2020) model\")\\n\\nuploaded = st.file_uploader(\"Upload an image\", type=[\\'png\\',\\'jpg\\',\\'jpeg\\'])\\n\\nif uploaded:\\n    pil_img = Image.open(uploaded).convert(\\'RGB\\')\\n\\n    # ðŸ”’ Limit image size to prevent OOM crash\\n    max_size = 512\\n    if pil_img.width > max_size or pil_img.height > max_size:\\n        pil_img.thumbnail((max_size, max_size))\\n        st.warning(f\"Image resized to {pil_img.size} to prevent out-of-memory issues.\")\\n\\n    st.image(pil_img, caption=\"Original Image\", use_column_width=True)\\n\\n    device = \\'cuda\\' if torch.cuda.is_available() else \\'cpu\\'\\n    if \\'model_info\\' not in st.session_state:\\n        with st.spinner(\\'Loading pretrained model...\\'):\\n            st.session_state[\\'model_info\\'] = load_model(device)\\n\\n    model_info = st.session_state[\\'model_info\\']\\n\\n    try:\\n        with st.spinner(\\'Compressing and reconstructing...\\'):\\n            x_hat_tensor, comp_bytes = compress_and_decompress(model_info, pil_img, device)\\n            rec_img = tensor_to_pil(x_hat_tensor)\\n            psnr, ssim = compute_metrics(pil_img, rec_img)\\n            bpp = (comp_bytes * 8) / (pil_img.width * pil_img.height)\\n\\n        col1, col2 = st.columns(2)\\n        col1.image(pil_img, caption=\"Original\")\\n        col2.image(rec_img, caption=\"Reconstructed\")\\n\\n        st.markdown(f\"**Bits per pixel:** {bpp:.4f}\")\\n        st.markdown(f\"**PSNR:** {psnr:.2f} dB\")\\n        st.markdown(f\"**SSIM:** {ssim:.4f}\")\\n\\n    except RuntimeError as e:\\n        st.error(f\"Compression failed: {str(e)}. Try a smaller image.\")\\n\"\"\"\\nopen(\"/content/app.py\",\"w\").write(app_py)\\nprint(\"âœ… Created app.py\")'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "utils_py = r\"\"\"\n",
        "import io, torch\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from skimage.metrics import peak_signal_noise_ratio as compare_psnr, structural_similarity as compare_ssim\n",
        "\n",
        "def load_image_as_tensor(pil_img):\n",
        "    transform = T.Compose([T.ToTensor()])\n",
        "    return transform(pil_img).unsqueeze(0)\n",
        "\n",
        "def tensor_to_pil(x):\n",
        "    x = x.detach().cpu().clamp(0,1)\n",
        "    if x.ndim == 4:\n",
        "        x = x[0]\n",
        "    arr = (x.numpy()*255).round().astype('uint8').transpose(1,2,0)\n",
        "    return Image.fromarray(arr)\n",
        "\n",
        "def compute_metrics(img1, img2):\n",
        "    a, b = np.array(img1).astype('float32'), np.array(img2).astype('float32')\n",
        "    psnr = compare_psnr(a, b, data_range=255)\n",
        "    ssim = compare_ssim(a, b, data_range=255, channel_axis=-1)\n",
        "    return psnr, ssim\n",
        "\n",
        "def pad_to_multiple_of(x, div=64):\n",
        "    _, _, h, w = x.shape\n",
        "    new_h = int(np.ceil(h/div)*div)\n",
        "    new_w = int(np.ceil(w/div)*div)\n",
        "    return F.pad(x, (0, new_w-w, 0, new_h-h)), (h, w)\n",
        "\"\"\"\n",
        "open(\"/content/utils.py\",\"w\").write(utils_py)\n",
        "print(\" Created utils.py\")\n",
        "\n",
        "app_py = r\"\"\"\n",
        "import streamlit as st\n",
        "import torch\n",
        "from PIL import Image\n",
        "import io\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from utils import load_image_as_tensor, tensor_to_pil, compute_metrics, pad_to_multiple_of\n",
        "from compressai.zoo import bmshj2018_factorized, mbt2018_mean, cheng2020_anchor\n",
        "\n",
        "# ---------------------------------------\n",
        "#  Streamlit Config\n",
        "# ---------------------------------------\n",
        "st.set_page_config(page_title=\"Transformer Image Compression\", layout=\"wide\")\n",
        "st.title(\" TIC Based Image Compression\")\n",
        "st.caption(\"Compare multiple pretrained models from CompressAI\")\n",
        "\n",
        "# ---------------------------------------\n",
        "#  Image Upload\n",
        "# ---------------------------------------\n",
        "uploaded = st.file_uploader(\"Upload an image\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "if not uploaded:\n",
        "    st.info(\"Upload an image to begin.\")\n",
        "    st.stop()\n",
        "\n",
        "# Get original file size\n",
        "original_size = len(uploaded.getvalue())\n",
        "pil_img = Image.open(uploaded).convert(\"RGB\")\n",
        "\n",
        "#  Limit image size to prevent OOM crash\n",
        "max_size = 1024\n",
        "if pil_img.width > max_size or pil_img.height > max_size:\n",
        "    pil_img.thumbnail((max_size, max_size))\n",
        "    st.warning(f\"Image resized to {pil_img.size} to prevent out-of-memory issues.\")\n",
        "\n",
        "col1, col2, col3 = st.columns(3)\n",
        "with col1:\n",
        "    st.image(pil_img, caption=f\"Original Image ({pil_img.width}Ã—{pil_img.height})\", use_column_width=True)\n",
        "\n",
        "with col2:\n",
        "    st.metric(\"Original File Size\", f\"{original_size/1024:.2f} KB\")\n",
        "\n",
        "with col3:\n",
        "    st.metric(\"Original Size\", f\"{original_size:,} bytes\")\n",
        "\n",
        "# ---------------------------------------\n",
        "#  Model Selector\n",
        "# ---------------------------------------\n",
        "st.markdown(\"###  Model Configuration\")\n",
        "model_name = st.selectbox(\n",
        "    \"Choose a pretrained model\",\n",
        "    [\n",
        "        \"bmshj2018_factorized (baseline)\",\n",
        "        \"mbt2018_mean (balanced)\",\n",
        "        \"cheng2020_anchor (stronger)\",\n",
        "    ],\n",
        "    help=\"Select the neural compression model to use\"\n",
        ")\n",
        "\n",
        "model_map = {\n",
        "    \"bmshj2018_factorized (baseline)\": bmshj2018_factorized,\n",
        "    \"mbt2018_mean (balanced)\": mbt2018_mean,\n",
        "    \"cheng2020_anchor (stronger)\": cheng2020_anchor,\n",
        "}\n",
        "\n",
        "# ---------------------------------------\n",
        "#  Quality Levels\n",
        "# ---------------------------------------\n",
        "st.markdown(\"###  Compression Settings\")\n",
        "qualities = st.multiselect(\n",
        "    \"Select quality levels to compare (1â€“6):\",\n",
        "    list(range(1, 7)),\n",
        "    default=[1, 3, 5],\n",
        "    help=\"Higher quality = better reconstruction but larger file size\"\n",
        ")\n",
        "\n",
        "if not qualities:\n",
        "    st.warning(\"Please select at least one quality level.\")\n",
        "    st.stop()\n",
        "\n",
        "# ---------------------------------------\n",
        "#  Compression Function\n",
        "# ---------------------------------------\n",
        "def compress_and_measure(model, x, original_size):\n",
        "    '''Compress image and measure compressed size'''\n",
        "    try:\n",
        "        # Compress the image\n",
        "        with torch.no_grad():\n",
        "            out_enc = model.compress(x)\n",
        "\n",
        "            # Calculate compressed size - handle different string formats\n",
        "            comp_bytes = 0\n",
        "            if isinstance(out_enc[\"strings\"], list):\n",
        "                for string_list in out_enc[\"strings\"]:\n",
        "                    if isinstance(string_list, list):\n",
        "                        for s in string_list:\n",
        "                            comp_bytes += len(s)\n",
        "                    else:\n",
        "                        comp_bytes += len(string_list)\n",
        "            else:\n",
        "                comp_bytes = len(out_enc[\"strings\"])\n",
        "\n",
        "            # Decompress to get reconstructed image\n",
        "            out_dec = model.decompress(out_enc[\"strings\"], out_enc[\"shape\"])\n",
        "            x_hat = out_dec[\"x_hat\"]\n",
        "\n",
        "            return comp_bytes, x_hat, True\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Compression error: {e}\")\n",
        "        # Return a fallback size estimate\n",
        "        fallback_size = max(original_size // 10, 1000)  # 10% of original or 1KB minimum\n",
        "        return fallback_size, x, False\n",
        "\n",
        "# ---------------------------------------\n",
        "#  Run Compression at Each Quality\n",
        "# ---------------------------------------\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "st.info(f\"Using device: {device.upper()}\")\n",
        "\n",
        "model_fn = model_map[model_name]\n",
        "results = []\n",
        "compressed_images = {}\n",
        "\n",
        "progress_bar = st.progress(0)\n",
        "status_text = st.empty()\n",
        "\n",
        "for i, q in enumerate(qualities):\n",
        "    status_text.text(f\"Compressing at quality {q}...\")\n",
        "\n",
        "    with st.spinner(f\"Loading model for quality {q}...\"):\n",
        "        try:\n",
        "            model = model_fn(quality=q, pretrained=True).eval().to(device)\n",
        "        except Exception as e:\n",
        "            st.error(f\"Failed to load model for quality {q}: {e}\")\n",
        "            continue\n",
        "\n",
        "    x = load_image_as_tensor(pil_img).to(device)\n",
        "    x_padded, orig_size = pad_to_multiple_of(x, div=64)\n",
        "    h, w = orig_size\n",
        "\n",
        "    try:\n",
        "        # Compress and get size\n",
        "        comp_bytes, x_hat_padded, success = compress_and_measure(model, x_padded, original_size)\n",
        "\n",
        "        # Crop back to original size\n",
        "        x_hat = x_hat_padded.clamp(0, 1)[..., :h, :w]\n",
        "        rec_img = tensor_to_pil(x_hat)\n",
        "\n",
        "        # Calculate metrics\n",
        "        psnr, ssim = compute_metrics(pil_img, rec_img)\n",
        "        bpp = (comp_bytes * 8) / (pil_img.width * pil_img.height)\n",
        "        saved_percent = 100 * (1 - (comp_bytes / original_size)) if original_size > 0 else 0\n",
        "        compression_ratio = original_size / comp_bytes if comp_bytes > 0 else 1\n",
        "\n",
        "        # Ensure reasonable values\n",
        "        comp_bytes = max(comp_bytes, 100)  # Minimum 100 bytes\n",
        "        saved_percent = min(max(saved_percent, -1000), 1000)  # Reasonable bounds\n",
        "        compression_ratio = min(max(compression_ratio, 0.1), 1000)  # Reasonable bounds\n",
        "\n",
        "        results.append({\n",
        "            \"Quality\": q,\n",
        "            \"Bits-per-pixel\": bpp,\n",
        "            \"PSNR (dB)\": psnr,\n",
        "            \"SSIM\": ssim,\n",
        "            \"Size Saved (%)\": saved_percent,\n",
        "            \"Compressed Size (bytes)\": comp_bytes,\n",
        "            \"Compressed Size (KB)\": comp_bytes / 1024,\n",
        "            \"Compression Ratio\": compression_ratio,\n",
        "            \"Success\": success\n",
        "        })\n",
        "\n",
        "        compressed_images[q] = rec_img\n",
        "\n",
        "        if success:\n",
        "            st.success(f\" Quality {q}: {comp_bytes/1024:.2f} KB (Saved: {saved_percent:.1f}%)\")\n",
        "        else:\n",
        "            st.warning(f\" Quality {q}: Estimated size {comp_bytes/1024:.2f} KB\")\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\" Compression failed for quality {q}: {str(e)}\")\n",
        "        continue\n",
        "\n",
        "    progress_bar.progress((i + 1) / len(qualities))\n",
        "\n",
        "status_text.text(\"Compression complete!\")\n",
        "progress_bar.empty()\n",
        "\n",
        "if not results:\n",
        "    st.error(\"No successful compressions. Please try different settings.\")\n",
        "    st.stop()\n",
        "\n",
        "# ---------------------------------------\n",
        "#  Display Results\n",
        "# ---------------------------------------\n",
        "st.markdown(\"##  Compression Results\")\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "# Metrics table\n",
        "st.markdown(\"### ðŸ“‹ Detailed Compression Metrics\")\n",
        "styled_df = df.style.format({\n",
        "    \"Bits-per-pixel\": \"{:.4f}\",\n",
        "    \"PSNR (dB)\": \"{:.2f}\",\n",
        "    \"SSIM\": \"{:.4f}\",\n",
        "    \"Size Saved (%)\": \"{:.1f}%\",\n",
        "    \"Compressed Size (bytes)\": \"{:,}\",\n",
        "    \"Compressed Size (KB)\": \"{:.2f}\",\n",
        "    \"Compression Ratio\": \"{:.2f}x\"\n",
        "}).background_gradient(subset=['PSNR (dB)', 'SSIM'], cmap='Blues')\\\n",
        " .background_gradient(subset=['Size Saved (%)'], cmap='Greens')\\\n",
        " .background_gradient(subset=['Compression Ratio'], cmap='Reds')\n",
        "\n",
        "st.dataframe(styled_df, use_container_width=True)\n",
        "\n",
        "# ---------------------------------------\n",
        "#  Size Comparison Dashboard\n",
        "# ---------------------------------------\n",
        "st.markdown(\"##  Size Comparison Dashboard\")\n",
        "\n",
        "if len(results) > 0:\n",
        "    best_compression_idx = df['Compressed Size (bytes)'].idxmin()\n",
        "    best_quality_idx = df['PSNR (dB)'].idxmax()\n",
        "\n",
        "    col1, col2, col3, col4 = st.columns(4)\n",
        "    with col1:\n",
        "        st.metric(\"Original Size\", f\"{original_size/1024:.2f} KB\")\n",
        "    with col2:\n",
        "        min_size = df['Compressed Size (KB)'].min()\n",
        "        st.metric(\"Smallest Compressed\", f\"{min_size:.2f} KB\")\n",
        "    with col3:\n",
        "        max_ratio = df['Compression Ratio'].max()\n",
        "        st.metric(\"Best Compression Ratio\", f\"{max_ratio:.2f}x\")\n",
        "    with col4:\n",
        "        avg_saved = df['Size Saved (%)'].mean()\n",
        "        st.metric(\"Average Size Saving\", f\"{avg_saved:.1f}%\")\n",
        "\n",
        "    # ---------------------------------------\n",
        "    # Size Visualization\n",
        "    # ---------------------------------------\n",
        "    st.markdown(\"###  Size Comparison Charts\")\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        # Size comparison bar chart\n",
        "        fig1, ax1 = plt.subplots(figsize=(10, 6))\n",
        "        original_kb = original_size / 1024\n",
        "        compressed_kb = df['Compressed Size (KB)'].values\n",
        "\n",
        "        x = np.arange(len(qualities))\n",
        "        width = 0.35\n",
        "\n",
        "        bars1 = ax1.bar(x - width/2, [original_kb] * len(qualities), width,\n",
        "                       label=f'Original ({original_kb:.2f} KB)', alpha=0.7, color='blue')\n",
        "        bars2 = ax1.bar(x + width/2, compressed_kb, width, label='Compressed', alpha=0.7, color='orange')\n",
        "\n",
        "        ax1.set_xlabel('Quality Level')\n",
        "        ax1.set_ylabel('File Size (KB)')\n",
        "        ax1.set_title('Original vs Compressed File Sizes')\n",
        "        ax1.set_xticks(x)\n",
        "        ax1.set_xticklabels([f'Q{q}' for q in qualities])\n",
        "        ax1.legend()\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "\n",
        "        # Add value labels on bars\n",
        "        for bar in bars2:\n",
        "            height = bar.get_height()\n",
        "            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
        "                    f'{height:.1f}KB', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        st.pyplot(fig1)\n",
        "\n",
        "    with col2:\n",
        "        # Compression ratio chart\n",
        "        fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
        "        ratios = df['Compression Ratio'].values\n",
        "\n",
        "        bars = ax2.bar(x, ratios, color='green', alpha=0.7)\n",
        "        ax2.set_xlabel('Quality Level')\n",
        "        ax2.set_ylabel('Compression Ratio')\n",
        "        ax2.set_title('Compression Ratio by Quality Level')\n",
        "        ax2.set_xticks(x)\n",
        "        ax2.set_xticklabels([f'Q{q}' for q in qualities])\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "\n",
        "        # Add value labels on bars\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax2.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
        "                    f'{height:.2f}x', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        st.pyplot(fig2)\n",
        "\n",
        "    # ---------------------------------------\n",
        "    # Visual Comparison\n",
        "    # ---------------------------------------\n",
        "    st.markdown(\"###  Visual Comparison\")\n",
        "\n",
        "    selected_quality = st.selectbox(\"Select quality to view reconstructed image:\", qualities)\n",
        "    if selected_quality in compressed_images:\n",
        "        rec_img = compressed_images[selected_quality]\n",
        "        selected_data = df[df['Quality'] == selected_quality].iloc[0]\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col1:\n",
        "            st.image(pil_img, caption=f\"Original Image ({original_size/1024:.2f} KB)\", use_column_width=True)\n",
        "        with col2:\n",
        "            st.image(rec_img,\n",
        "                    caption=f\"Reconstructed Q{selected_quality} ({selected_data['Compressed Size (KB)']:.2f} KB, \"\n",
        "                           f\"Saved: {selected_data['Size Saved (%)']:.1f}%)\",\n",
        "                    use_column_width=True)\n",
        "\n",
        "        # Show compression info\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "        with col1:\n",
        "            st.metric(\"Size Reduction\", f\"{selected_data['Size Saved (%)']:.1f}%\")\n",
        "        with col2:\n",
        "            st.metric(\"Compression Ratio\", f\"{selected_data['Compression Ratio']:.2f}x\")\n",
        "        with col3:\n",
        "            st.metric(\"Quality Score\", f\"{selected_data['PSNR (dB)']:.2f} dB\")\n",
        "\n",
        "        # Show difference map\n",
        "    st.markdown(\"####  Difference Map\")\n",
        "    diff_fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
        "    orig_arr = np.array(pil_img).astype(float)\n",
        "    rec_arr = np.array(rec_img).astype(float)\n",
        "    diff = np.abs(orig_arr - rec_arr)\n",
        "    im = ax.imshow(diff.mean(axis=2), cmap='hot')\n",
        "    ax.set_title(f\"Absolute Difference Map (Quality {selected_quality})\")\n",
        "    ax.axis('off')\n",
        "    plt.colorbar(im, ax=ax, label='Difference Intensity')\n",
        "    st.pyplot(diff_fig)\n",
        "\n",
        "\n",
        "\n",
        "    # ---------------------------------------\n",
        "    #  Download Section\n",
        "    # ---------------------------------------\n",
        "    st.markdown(\"## ðŸ’¾ Download Results\")\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        # Download reconstructed image\n",
        "        if selected_quality in compressed_images:\n",
        "            rec_img = compressed_images[selected_quality]\n",
        "            buf = io.BytesIO()\n",
        "            rec_img.save(buf, format=\"PNG\", optimize=True)\n",
        "            st.download_button(\n",
        "                label=f\"Download Reconstructed (Q{selected_quality}) - {selected_data['Compressed Size (KB)']:.1f} KB\",\n",
        "                data=buf.getvalue(),\n",
        "                file_name=f\"reconstructed_q{selected_quality}.png\",\n",
        "                mime=\"image/png\",\n",
        "            )\n",
        "\n",
        "    with col2:\n",
        "        # Download enhanced metrics CSV\n",
        "        csv_data = df.to_csv(index=False).encode(\"utf-8\")\n",
        "        st.download_button(\n",
        "            label=\"Download Full Metrics (CSV)\",\n",
        "            data=csv_data,\n",
        "            file_name=\"compression_metrics.csv\",\n",
        "            mime=\"text/csv\",\n",
        "        )\n",
        "\n",
        "# ---------------------------------------\n",
        "# ðŸ“š Model Information\n",
        "# ---------------------------------------\n",
        "st.markdown(\"## ðŸ“š Model Information\")\n",
        "\n",
        "model_descriptions = {\n",
        "    \"bmshj2018_factorized (baseline)\": '''\n",
        "    **BMSE2018-factorized**: Baseline model using factorized priors for entropy modeling.\n",
        "    Good balance between complexity and performance.\n",
        "    ''',\n",
        "    \"mbt2018_mean (balanced)\": '''\n",
        "    **MBT2018-mean**: Uses mean-scale hyperpriors for improved entropy modeling.\n",
        "    Better performance than factorized priors with moderate complexity.\n",
        "    ''',\n",
        "    \"cheng2020_anchor (stronger)\": '''\n",
        "    **Cheng2020-anchor**: State-of-the-art model using anchor-based quantization and\n",
        "    Gaussian mixture models for entropy modeling. Provides excellent rate-distortion performance.\n",
        "    '''\n",
        "}\n",
        "\n",
        "st.info(model_descriptions[model_name])\n",
        "\"\"\"\n",
        "open(\"/content/app.py\",\"w\").write(app_py)\n",
        "print(\"âœ… Created fixed app with compression function inside app.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKBf3ndS0fxR",
        "outputId": "93c6764d-11ce-4da3-df0b-cdb8c7d23eac"
      },
      "id": "RKBf3ndS0fxR",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Created utils.py\n",
            "âœ… Created fixed app with compression function inside app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "512c89e7",
      "metadata": {
        "id": "512c89e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87cc2be8-397a-4150-9ac1-536ebe5e9010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŒ Streamlit App is live at: https://mirkily-acarpous-dion.ngrok-free.dev\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\n",
            "\n",
            "  You can now view your Streamlit app in your browser.\n",
            "\n",
            "  Local URL: http://localhost:8501\n",
            "  Network URL: http://172.28.0.12:8501\n",
            "  External URL: http://34.45.77.210:8501\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "import time\n",
        "\n",
        "ngrok.kill()\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"ðŸŒ Streamlit App is live at: {public_url.public_url}\")\n",
        "\n",
        "# Start Streamlit server\n",
        "!streamlit run /content/app.py --server.port 8501 > /content/logs.txt 2>&1 &\n",
        "\n",
        "# Wait for it to start\n",
        "time.sleep(5)\n",
        "!tail -n 15 /content/logs.txt"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}